text2vec-package	text2vec
%>%	reexports
as.lda_c	as.lda_c
char_tokenizer	tokenizers
check_analogy_accuracy	check_analogy_accuracy
create_corpus	create_corpus
create_dtm	create_dtm
create_dtm.itoken	create_dtm
create_dtm.list	create_dtm
create_tcm	create_tcm
create_tcm.itoken	create_tcm
create_tcm.list	create_tcm
create_vocabulary	create_vocabulary
create_vocabulary.character	create_vocabulary
create_vocabulary.itoken	create_vocabulary
create_vocabulary.list	create_vocabulary
dist2	distances
distances	distances
fit	fit
fit.Matrix	fit
fit.matrix	fit
fit_transform	fit_transform
fit_transform.Matrix	fit_transform
fit_transform.matrix	fit_transform
get_dtm	get_dtm
get_idf	get_idf
get_tcm	get_tcm
get_tf	get_tf
GlobalVectors	GlobalVectors
GloVe	GlobalVectors
glove	glove
hash_vectorizer	vectorizers
idir	ifiles
ifiles	ifiles
itoken	itoken
itoken.character	itoken
itoken.iterator	itoken
itoken.list	itoken
LatentDirichletAllocation	LatentDirichletAllocation
LatentSemanticAnalysis	LatentSemanticAnalysis
LDA	LatentDirichletAllocation
LSA	LatentSemanticAnalysis
movie_review	movie_review
normalize	normalize
pdist2	distances
prepare_analogy_questions	prepare_analogy_questions
prune_vocabulary	prune_vocabulary
psim2	similarities
reexports	reexports
regexp_tokenizer	tokenizers
RelaxedWordMoversDistance	RelaxedWordMoversDistance
RWMD	RelaxedWordMoversDistance
sim2	similarities
similarities	similarities
space_tokenizer	tokenizers
split_into	split_into
text2vec	text2vec
TfIdf	TfIdf
tokenizers	tokenizers
transform	transform
transform.Matrix	transform
transform.matrix	transform
transform_binary	transform_tf
transform_filter_commons	transform_filter_commons
transform_tf	transform_tf
transform_tfidf	transform_tf
vectorizers	vectorizers
vocabulary	create_vocabulary
vocab_vectorizer	vectorizers
word_tokenizer	tokenizers
